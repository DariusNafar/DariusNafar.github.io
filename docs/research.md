# Research

### Assessing Trust & Relationship Building in Human–AI Interactions 
> _Mar 2025 – Present_

- Designed prompts, an A/B-testing framework, and a full-stack agentic chatbot (FastAPI, LangChain) to assess trust.
- Doubled user engagement and improved task completion by 30% among 12 pilot users in Phase 1 via optimal prompting strategy.

### Learning vs. Retrieval: The Role of In-Context Examples in Regression with LLMs 
>_Jan 2024 – Dec 2024_

- Proposed a framework to identify and manipulate LLMs’ in-context learning (ICL) mechanisms.
- Achieved up to 90% data efficiency; published at NAACL 2025 (_Outstanding Paper Award_).

### Reasoning over Uncertain Text by Generative Large Language Models 
>_May 2023 – Jul 2025_

- Created a Bayesian-inference dataset; prompt-engineered coding methods improved accuracy by 40%, leading to an AAAI 2025 publication.
- Used LLMs to emulate expert probability judgments, improving Bayesian-network accuracy by 7%; submitted to AAAI 2026.

### DomiKnowS: Integrating Symbolic Domain Knowledge in Deep Learning 
>_Jan 2021 – Present_

- Researched and unified constraint-utilization methods into a library; EMNLP 2021 (Demo).
- Built the first benchmark for evaluating neuro-symbolic methods and embeddings; AAAI 2023.
- Architected an interactive deep-learning coding pipeline (GPT-4) that boosted developer speed by 500%; NeSy 2024.
- Designed an end-to-end benchmark for open-source NeSy frameworks quantifying engineering effort with system KPIs; submitted to JAIR.
