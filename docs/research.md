# Research

### Interactive Agentic Code Generation with to fine-tune LLMs
>_Aug 2024 - Present

- Build an interactive agentic coder with LangGraph, FastAPI, \& RAG to generate and debug code to fine-tune collaborative LLMs
- Train LLMs using reinforcement learning (GRPO and DPO), reducing model size by 45\%. Planned submission for JAIR

### Human–AI Trust & Relationship Modeling in Conversational Agents 
>_Mar 2025 – Oct 2025_

- Designed prompts, an A/B-testing framework, and a full-stack agentic chatbot (FastAPI, LangChain) to assess trust.
- Doubled user engagement and improved task completion by 30% among 12 pilot users in Phase 1 via optimal prompting strategy.

### In-Context Learning vs Retrieval for Data-Efficient LLM Reasoning
>_Jan 2024 – Dec 2024_

- Proposed a framework to identify and manipulate LLMs’ in-context learning (ICL) mechanisms.
- Achieved up to 90% data efficiency; published at NAACL 2025 (_Outstanding Paper Award_).

### Reasoning over Text that includes Uncertainties using Generative LLMs
>_May 2023 – Jul 2025_

- Created a Bayesian-inference dataset; prompt-engineered coding methods improved accuracy by 40%, leading to an AAAI 2025 publication.
- Used LLMs to emulate expert probability judgments, improving Bayesian-network accuracy by 7%; submitted to AAAI 2026.

### Developing a Neuro-Symbolic Deep Learning Library for Constraint-Based Learning 
>_Jan 2021 – Sept 2025_

- Researched and unified constraint-utilization methods into a library; EMNLP 2021 (Demo).
- Built the first benchmark for evaluating neuro-symbolic methods and embeddings; AAAI 2023.
- Architected an interactive deep-learning coding pipeline (GPT-4) that boosted developer speed by 500%; NeSy 2024.